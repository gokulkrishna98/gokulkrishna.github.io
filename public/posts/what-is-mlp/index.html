<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>What is MLP? | Gokul's Website</title>
<meta name=keywords content><meta name=description content="Multi-Layer Perceptron (MLP) stands as one of the pioneering architectures in deep learning neural networks (DNN).
Renowned for its power and simplicity, MLPs have laid the foundation for many subsequent advancements in the field.
In this article, we delve into the science behind MLPs, explore their diverse applications, and walk through the
process of coding a basic classification neural network using this influential architecture.
Setup
How do humans learn? We tackle real-world problems by interpreting signals and information based on our own understanding of the world, using our brains to devise solutions. However, computers, while powerful, simply process numbers rather than raw signals efficiently (for now!). So, what exactly is meant by machine learning if computers cannot directly interpret these signals? Essentially, it involves mapping certain numerical computations to solve real-world problems. How do we achieve this? By translating real-world phenomena into numerical representations that computers can comprehend and manipulate. For instance, images are converted into pixels, essentially sets of numbers, while textual sentences are transformed into tokens, also represented by numbers."><meta name=author content="Gokul"><link rel=canonical href=http://localhost:1313/posts/what-is-mlp/><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/what-is-mlp/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="http://localhost:1313/posts/what-is-mlp/"><meta property="og:site_name" content="Gokul's Website"><meta property="og:title" content="What is MLP?"><meta property="og:description" content="Multi-Layer Perceptron (MLP) stands as one of the pioneering architectures in deep learning neural networks (DNN). Renowned for its power and simplicity, MLPs have laid the foundation for many subsequent advancements in the field. In this article, we delve into the science behind MLPs, explore their diverse applications, and walk through the process of coding a basic classification neural network using this influential architecture.
Setup How do humans learn? We tackle real-world problems by interpreting signals and information based on our own understanding of the world, using our brains to devise solutions. However, computers, while powerful, simply process numbers rather than raw signals efficiently (for now!). So, what exactly is meant by machine learning if computers cannot directly interpret these signals? Essentially, it involves mapping certain numerical computations to solve real-world problems. How do we achieve this? By translating real-world phenomena into numerical representations that computers can comprehend and manipulate. For instance, images are converted into pixels, essentially sets of numbers, while textual sentences are transformed into tokens, also represented by numbers."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-03-07T00:00:00+00:00"><meta property="article:modified_time" content="2024-03-07T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="What is MLP?"><meta name=twitter:description content="Multi-Layer Perceptron (MLP) stands as one of the pioneering architectures in deep learning neural networks (DNN).
Renowned for its power and simplicity, MLPs have laid the foundation for many subsequent advancements in the field.
In this article, we delve into the science behind MLPs, explore their diverse applications, and walk through the
process of coding a basic classification neural network using this influential architecture.
Setup
How do humans learn? We tackle real-world problems by interpreting signals and information based on our own understanding of the world, using our brains to devise solutions. However, computers, while powerful, simply process numbers rather than raw signals efficiently (for now!). So, what exactly is meant by machine learning if computers cannot directly interpret these signals? Essentially, it involves mapping certain numerical computations to solve real-world problems. How do we achieve this? By translating real-world phenomena into numerical representations that computers can comprehend and manipulate. For instance, images are converted into pixels, essentially sets of numbers, while textual sentences are transformed into tokens, also represented by numbers."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"What is MLP?","item":"http://localhost:1313/posts/what-is-mlp/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"What is MLP?","name":"What is MLP?","description":"Multi-Layer Perceptron (MLP) stands as one of the pioneering architectures in deep learning neural networks (DNN). Renowned for its power and simplicity, MLPs have laid the foundation for many subsequent advancements in the field. In this article, we delve into the science behind MLPs, explore their diverse applications, and walk through the process of coding a basic classification neural network using this influential architecture.\nSetup How do humans learn? We tackle real-world problems by interpreting signals and information based on our own understanding of the world, using our brains to devise solutions. However, computers, while powerful, simply process numbers rather than raw signals efficiently (for now!). So, what exactly is meant by machine learning if computers cannot directly interpret these signals? Essentially, it involves mapping certain numerical computations to solve real-world problems. How do we achieve this? By translating real-world phenomena into numerical representations that computers can comprehend and manipulate. For instance, images are converted into pixels, essentially sets of numbers, while textual sentences are transformed into tokens, also represented by numbers.\n","keywords":[],"articleBody":"Multi-Layer Perceptron (MLP) stands as one of the pioneering architectures in deep learning neural networks (DNN). Renowned for its power and simplicity, MLPs have laid the foundation for many subsequent advancements in the field. In this article, we delve into the science behind MLPs, explore their diverse applications, and walk through the process of coding a basic classification neural network using this influential architecture.\nSetup How do humans learn? We tackle real-world problems by interpreting signals and information based on our own understanding of the world, using our brains to devise solutions. However, computers, while powerful, simply process numbers rather than raw signals efficiently (for now!). So, what exactly is meant by machine learning if computers cannot directly interpret these signals? Essentially, it involves mapping certain numerical computations to solve real-world problems. How do we achieve this? By translating real-world phenomena into numerical representations that computers can comprehend and manipulate. For instance, images are converted into pixels, essentially sets of numbers, while textual sentences are transformed into tokens, also represented by numbers.\nLet’s set up a scenario: Imagine we have a real-world problem, such as image classification. We start with an input, say an image, and through cognitive processes, we identify and label what it represents. Next, we translate this human-generated understanding into a format understandable by computers. Here are the steps:\nConvert the image into numbers (input). Convert the output text into numbers (labels). Establish a relationship between them through machine learning. The mathematical concept of functions forms the foundation of machine learning, representing relationships between sets of numbers. The set of inputs is termed the domain, while the set of outputs is called the range. Suppose, by some magic, we acquire a set of input and output pairs. It becomes apparent that predicting the exact function from these samples is impossible; the best we can do is approximate it. How? Here’s a simplified approach:\nRandomly (or through heuristics), select a family of functions (e.g., polynomial, sine, exponential). Identify all functions capable of mapping these input-output pairs (represented by the training data space). Choose the best function from this set. Steps 1 and 2 are relatively straightforward. But how do we tackle step 3? We employ another function, an objective function, which provides a score proportional to the function’s effectiveness. This objective function, often called the loss, aims to minimize the discrepancy between predicted and actual values for a given input. Leveraging calculus, we limit ourselves to continuous functions in step 1. If the loss is also continuous, we can solve the minimization problem by computing the gradient of the loss and moving in the direction of its minimum. Learn about Gradient descent.\nAn important concept to grasp is that any continuous function can be approximated using polynomial functions (Taylor series approximation).\nAt this juncture, the setup may seem mundane, but it sets the stage for understanding how MLP fits into this framework:\nMLP is one of the families of functions (Step 1) we choose to solve a problem. Typically, an MLP represents a complex continuous function (involving dot producs to form another vector) with activations. This implies that MLP is continuous, and we can compute its gradient. We utilize gradients to minimize the loss, thereby identifying the best MLP parameters. How does this MLP Look ? The image below depicts the structure of an MLP network, but to the uninitiated eye, the jumble of lines and nodes can seem perplexing. What exactly do these elements represent?\nLet’s break down the components visible in the image:\nEdges: These are the lines connecting various nodes in the network. Neuron: Each circle or node represents a neuron in the network. Layers: The network comprises different layers, including input, hidden, and output layers. Now, let’s delve into the structure and concepts underlying these components. Edges/Connections The edges within this network symbolize numerical values, serving as representations of real-world problems that the network operates upon. These numerical representations can take various forms, but for simplicity, let’s consider them as numbers. Each node in the layerr forms a set of numbers, a vector. This vectorization facilitates efficient computation during inference.\nWhen each neuron is connected to every other neuron in the subsequent layer, we refer to this arrangement as a fully connected layer.\nNodes These units are termed neurons, akin to their biological counterparts. But what exactly do they do?\nEach neuron stores a numerical value for every input connection it receives. Consequently, every neuron possesses a set of these numbers, which collectively form vectors known as the neuron’s weights. One can think of these weights as reflecting the importance that each input holds for the neuron. To compute an output from the neuron, we perform a weighted sum of the input values by multiplying them with their corresponding weights and then adding them together. In essence, this operation boils down to the vector dot product between the input vector (formed by the input connections) and the weight vector.\nTo imbue neurons with greater expressive power, we introduce an activation operation on the output. This activation operation introduces non-linearity, expanding the repertoire of functions that the neurons can represent.\nBias We include a bias number for each neuron because it acts as a reference point from which learning can commence. If we were to initialize all weights to zero, the network would encounter difficulties in learning. Alternatively, utilizing random initialization introduces inherent bias, providing the network with diverse starting conditions essential for effective learning.\nLayer We can observe that neurons can be grouped based on their positional similarity within the network. The layer that directly receives input numbers is termed the input layer, while the layer responsible for outputting the predicted values is referred to as the output layer. In contrast, the intermediate layers lack any direct physical interpretation. Instead, they represent mappings of intermediate functions within the numerical space. Consequently, these layers are termed hidden layers.\nWhy MLP is relevant ? MLP plays the role of universal function approximator, it is because the model can represent any continuous function given enough neurons. This makes it a powerful tool.\nUsing pytorch to implement MLP 1. Imports import torch import torchvision import torchvision.transforms as transforms 2. Defining Transforms and Loading the Dataset. Purpose of Transform:\nConvert the raw pixels to Tensors. Normalize the data from -1 to 1. transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))] ) batch_size = 1 trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2) testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2) classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') print(f\"shape of images: {next(iter(trainloader))[0].shape}\") print(f\"shape of labels: {next(iter(trainloader))[1].shape}\") The torchvision data set gives pixel value from 0 to 1, but we create -1 to 1 (helps in utilizing relu and other advantages). The first tuple contains mean across each channel and the second tuple contains standard deviation across each channel. We then for each value normlize using this formula:\n$$ \\hat{x} = \\dfrac{x - mean}{std} $$\nDoing this on values with range [0, 1] using mean=0.5 and std=0.5, results in normalized value from [-1, 1]\n3. Defining our MLP architecture We define our MLP. The input image has the shape (1, 3, 32, 32), i.e image with height=32px, width=32px and three channels (R,G,B). We assign each pixel to a neuron in the input layer, to do that we flatten the image to 1d tensor with shape (3072). Now we use nn.Linear to implement the input, hidden and output layer. Check out the documentation here. It is essentially dot-product plus adding bias. Then we add Relu activation.\n#defining mlp import torch.nn as nn import torch.nn.functional as F class MLP(nn.Module): def __init__(self): super().__init__() self.flatten = nn.Flatten() self.input_layer = nn.Linear(3*32*32, 256) self.hidden_layer = nn.Linear(256, 128) self.output_layer = nn.Linear(128, 10) self.relu = nn.ReLU() def forward(self, x): x = self.flatten(x) x = self.relu(self.input_layer(x)) x = self.relu(self.hidden_layer(x)) x = self.output_layer(x) return x net = MLP() 4. Define the loss and optimizer import torch.optim as optim crit = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) You might have noticed that the output of MLP is a 1d tensor of 10 elements, but label we just have 1 label. There is no sync. If we attempt to solve the problem like linear regression there will be significant less learning. Instead we treate output of MLP as logits. The logit is a tensor, which gives probability of a given image belonging to particular label. The CrossEntropyLoss helps in coverting labels to logits and we operate the loss based on applying softmax function, which gives probability. Read further about softmax.\nwe use stochastic gradient descent to reach the local minima, that is update the parameters of the model through differentiation and reach best pair of values.\n5. Training for epoch in range(5): running_loss = 0.0 for i, data in enumerate(trainloader, 0): inputs, labels = data optimizer.zero_grad() outputs = net(inputs) # print(f\"output shape{outputs.shape}\") loss = crit(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() if i % 2000 == 1999: print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}') running_loss = 0.0 Perfomring SGD. Calculate loss, then compute gradient using backward (read about Autograd here). Now update the params based on this gradient. Gradient descent formula (read about it). $$ \\theta_{j+1} = \\theta_j - \\alpha \\nabla J(\\theta_j) $$\n6. Evaluate the Dataset. correct = 0 total = 0 # since we're not training, we don't need to calculate the gradients for our outputs with torch.no_grad(): for data in testloader: images, labels = data # calculate outputs by running images through the network outputs = net(images) # the class with the highest energy is what we choose as prediction _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %') Output\nAccuracy of the network on the 10000 test images: 51 % 7. Save the Model PATH = './cifar_MLP.pth' torch.save(net.state_dict(), PATH) Conclusion We have seen what is MLP, why it is ubiquitos and powerful. We trained a MLP model using pytorch through SGD. This achieves 51 % accuracy on CIFAR-10 test dataset, which is pretty good for such a small and simple model. Well this approach many flaws, in the whole model we treat each pixel independently we do know infer any info of channels, neighbouring pixel relationship (we flatten) etc. But it still gives a competitive performance. In future we will see how CNN (new type of DNN which got popular in 2010s solves these issue). Next we will check more about pytorch ecosystem and see if we can make this model production ready.\n","wordCount":"1771","inLanguage":"en","datePublished":"2024-03-07T00:00:00Z","dateModified":"2024-03-07T00:00:00Z","author":{"@type":"Person","name":"Gokul"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/what-is-mlp/"},"publisher":{"@type":"Organization","name":"Gokul's Website","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Gokul's Website (Alt + H)">Gokul's Website</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">What is MLP?</h1><div class=post-meta><span title='2024-03-07 00:00:00 +0000 UTC'>March 7, 2024</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;1771 words&nbsp;·&nbsp;Gokul</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#setup>Setup</a></li><li><a href=#how-does-this-mlp-look->How does this MLP Look ?</a><ul><li><a href=#edgesconnections>Edges/Connections</a></li><li><a href=#nodes>Nodes</a></li><li><a href=#bias>Bias</a></li><li><a href=#layer>Layer</a></li></ul></li><li><a href=#why-mlp-is-relevant->Why MLP is relevant ?</a></li><li><a href=#using-pytorch-to-implement-mlp>Using pytorch to implement MLP</a><ul><li><a href=#1-imports>1. Imports</a></li><li><a href=#2-defining-transforms-and-loading-the-dataset>2. Defining Transforms and Loading the Dataset.</a></li><li><a href=#3-defining-our-mlp-architecture>3. Defining our MLP architecture</a></li><li><a href=#4-define-the-loss-and-optimizer>4. Define the loss and optimizer</a></li><li><a href=#5-training>5. Training</a></li><li><a href=#6-evaluate-the-dataset>6. Evaluate the Dataset.</a></li><li><a href=#7-save-the-model>7. Save the Model</a></li></ul></li><li><a href=#conclusion>Conclusion</a></li></ul></nav></div></details></div><div class=post-content><p>Multi-Layer Perceptron (MLP) stands as one of the pioneering architectures in deep learning neural networks (DNN).
Renowned for its power and simplicity, MLPs have laid the foundation for many subsequent advancements in the field.
In this article, we delve into the science behind MLPs, explore their diverse applications, and walk through the
process of coding a basic classification neural network using this influential architecture.</p><h2 id=setup>Setup<a hidden class=anchor aria-hidden=true href=#setup>#</a></h2><p>How do humans learn? We tackle real-world problems by interpreting signals and information based on our own understanding of the world, using our brains to devise solutions. However, computers, while powerful, simply process numbers rather than raw signals efficiently (for now!). So, what exactly is meant by machine learning if computers cannot directly interpret these signals? Essentially, it involves mapping certain numerical computations to solve real-world problems. How do we achieve this? By translating real-world phenomena into numerical representations that computers can comprehend and manipulate. For instance, images are converted into pixels, essentially sets of numbers, while textual sentences are transformed into tokens, also represented by numbers.</p><p>Let&rsquo;s set up a scenario: Imagine we have a real-world problem, such as image classification. We start with an input, say an image, and through cognitive processes, we identify and label what it represents. Next, we translate this human-generated understanding into a format understandable by computers. Here are the steps:</p><ol><li>Convert the image into numbers (input).</li><li>Convert the output text into numbers (labels).</li><li>Establish a relationship between them through machine learning.</li></ol><p>The mathematical concept of functions forms the foundation of machine learning, representing relationships between sets of numbers. The set of inputs is termed the domain, while the set of outputs is called the range. Suppose, by some magic, we acquire a set of input and output pairs. It becomes apparent that predicting the exact function from these samples is impossible; the best we can do is approximate it. How? Here&rsquo;s a simplified approach:</p><ol><li>Randomly (or through heuristics), select a family of functions (e.g., polynomial, sine, exponential).</li><li>Identify all functions capable of mapping these input-output pairs (represented by the training data space).</li><li>Choose the best function from this set.</li></ol><p>Steps 1 and 2 are relatively straightforward. But how do we tackle step 3? We employ another function, an objective function, which provides a score proportional to the function&rsquo;s effectiveness. This objective function, often called the loss, aims to minimize the discrepancy between predicted and actual values for a given input. Leveraging calculus, we limit ourselves to continuous functions in step 1. If the loss is also continuous, we can solve the minimization problem by computing the gradient of the loss and moving in the direction of its minimum. Learn about Gradient descent.</p><p>An important concept to grasp is that any continuous function can be approximated using polynomial functions (Taylor series approximation).</p><p>At this juncture, the setup may seem mundane, but it sets the stage for understanding how MLP fits into this framework:</p><ul><li>MLP is one of the families of functions (Step 1) we choose to solve a problem.</li><li>Typically, an MLP represents a complex continuous function (involving dot producs to form another vector) with activations.</li><li>This implies that MLP is continuous, and we can compute its gradient.</li><li>We utilize gradients to minimize the loss, thereby identifying the best MLP parameters.</li></ul><h2 id=how-does-this-mlp-look->How does this MLP Look ?<a hidden class=anchor aria-hidden=true href=#how-does-this-mlp-look->#</a></h2><p>The image below depicts the structure of an MLP network, but to the uninitiated eye, the jumble of lines and nodes can seem perplexing.
What exactly do these elements represent?</p><p><img alt=mlp loading=lazy src=/images/mlp_image.jpg></p><p>Let&rsquo;s break down the components visible in the image:</p><ul><li>Edges: These are the lines connecting various nodes in the network.</li><li>Neuron: Each circle or node represents a neuron in the network.</li><li>Layers: The network comprises different layers, including input, hidden, and output layers.
Now, let&rsquo;s delve into the structure and concepts underlying these components.</li></ul><h3 id=edgesconnections>Edges/Connections<a hidden class=anchor aria-hidden=true href=#edgesconnections>#</a></h3><p>The edges within this network symbolize numerical values, serving as representations of real-world problems that the network operates upon. These numerical representations can take various forms, but for simplicity, let&rsquo;s consider them as numbers. Each node in the layerr forms a set of numbers, a vector. This vectorization facilitates efficient computation during inference.</p><p>When each neuron is connected to every other neuron in the subsequent layer, we refer to this arrangement as a fully connected layer.</p><h3 id=nodes>Nodes<a hidden class=anchor aria-hidden=true href=#nodes>#</a></h3><p>These units are termed neurons, akin to their biological counterparts. But what exactly do they do?</p><p>Each neuron stores a numerical value for every input connection it receives. Consequently, every neuron possesses a set of these numbers, which collectively form vectors known as the neuron&rsquo;s weights. One can think of these weights as reflecting the importance that each input holds for the neuron. To compute an output from the neuron, we perform a weighted sum of the input values by multiplying them with their corresponding weights and then adding them together. In essence, this operation boils down to the vector dot product between the input vector (formed by the input connections) and the weight vector.</p><p>To imbue neurons with greater expressive power, we introduce an activation operation on the output. This activation operation introduces non-linearity, expanding the repertoire of functions that the neurons can represent.</p><h3 id=bias>Bias<a hidden class=anchor aria-hidden=true href=#bias>#</a></h3><p>We include a bias number for each neuron because it acts as a reference point from which learning can commence. If we were to initialize all weights to zero, the network would encounter difficulties in learning. Alternatively, utilizing random initialization introduces inherent bias, providing the network with diverse starting conditions essential for effective learning.</p><h3 id=layer>Layer<a hidden class=anchor aria-hidden=true href=#layer>#</a></h3><p>We can observe that neurons can be grouped based on their positional similarity within the network. The layer that directly receives input numbers is termed the input layer, while the layer responsible for outputting the predicted values is referred to as the output layer. In contrast, the intermediate layers lack any direct physical interpretation. Instead, they represent mappings of intermediate functions within the numerical space. Consequently, these layers are termed hidden layers.</p><p><img alt=mlp_neuron loading=lazy src=/images/mlp_neuron.jpg></p><h2 id=why-mlp-is-relevant->Why MLP is relevant ?<a hidden class=anchor aria-hidden=true href=#why-mlp-is-relevant->#</a></h2><p>MLP plays the role of universal function approximator, it is because the model can represent any continuous function given enough neurons. This makes it
a powerful tool.</p><h2 id=using-pytorch-to-implement-mlp>Using pytorch to implement MLP<a hidden class=anchor aria-hidden=true href=#using-pytorch-to-implement-mlp>#</a></h2><h3 id=1-imports>1. Imports<a hidden class=anchor aria-hidden=true href=#1-imports>#</a></h3><pre tabindex=0><code>import torch
import torchvision
import torchvision.transforms as transforms
</code></pre><h3 id=2-defining-transforms-and-loading-the-dataset>2. Defining Transforms and Loading the Dataset.<a hidden class=anchor aria-hidden=true href=#2-defining-transforms-and-loading-the-dataset>#</a></h3><p>Purpose of Transform:</p><ol><li>Convert the raw pixels to Tensors.</li><li>Normalize the data from -1 to 1.</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>transform <span style=color:#f92672>=</span> transforms<span style=color:#f92672>.</span>Compose(
</span></span><span style=display:flex><span>    [transforms<span style=color:#f92672>.</span>ToTensor(),
</span></span><span style=display:flex><span>     transforms<span style=color:#f92672>.</span>Normalize((<span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>0.5</span>), (<span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>0.5</span>))]
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>batch_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>trainset <span style=color:#f92672>=</span> torchvision<span style=color:#f92672>.</span>datasets<span style=color:#f92672>.</span>CIFAR10(root<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;./data&#34;</span>, train<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, 
</span></span><span style=display:flex><span>			download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, transform<span style=color:#f92672>=</span>transform)
</span></span><span style=display:flex><span>trainloader <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>utils<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>DataLoader(trainset, 
</span></span><span style=display:flex><span>			batch_size<span style=color:#f92672>=</span>batch_size, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, num_workers<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>testset <span style=color:#f92672>=</span> torchvision<span style=color:#f92672>.</span>datasets<span style=color:#f92672>.</span>CIFAR10(root<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;./data&#34;</span>, train<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, 
</span></span><span style=display:flex><span>			download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, transform<span style=color:#f92672>=</span>transform)
</span></span><span style=display:flex><span>testloader <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>utils<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>DataLoader(testset, 
</span></span><span style=display:flex><span>			batch_size<span style=color:#f92672>=</span>batch_size, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, num_workers<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>classes <span style=color:#f92672>=</span> (<span style=color:#e6db74>&#39;plane&#39;</span>, <span style=color:#e6db74>&#39;car&#39;</span>, <span style=color:#e6db74>&#39;bird&#39;</span>, <span style=color:#e6db74>&#39;cat&#39;</span>,
</span></span><span style=display:flex><span>           <span style=color:#e6db74>&#39;deer&#39;</span>, <span style=color:#e6db74>&#39;dog&#39;</span>, <span style=color:#e6db74>&#39;frog&#39;</span>, <span style=color:#e6db74>&#39;horse&#39;</span>, <span style=color:#e6db74>&#39;ship&#39;</span>, <span style=color:#e6db74>&#39;truck&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;shape of images: </span><span style=color:#e6db74>{</span>next(iter(trainloader))[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>shape<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;shape of labels: </span><span style=color:#e6db74>{</span>next(iter(trainloader))[<span style=color:#ae81ff>1</span>]<span style=color:#f92672>.</span>shape<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><p>The torchvision data set gives pixel value from 0 to 1, but we create -1 to 1 (helps in utilizing relu and other advantages).
The first tuple contains mean across each channel and the second tuple contains standard deviation across each channel.
We then for each value normlize using this formula:</p><p>$$ \hat{x} = \dfrac{x - mean}{std} $$</p><p>Doing this on values with range [0, 1] using mean=0.5 and std=0.5, results in normalized value from [-1, 1]</p><h3 id=3-defining-our-mlp-architecture>3. Defining our MLP architecture<a hidden class=anchor aria-hidden=true href=#3-defining-our-mlp-architecture>#</a></h3><p>We define our MLP. The input image has the shape (1, 3, 32, 32), i.e image with height=32px, width=32px and three channels (R,G,B).
We assign each pixel to a neuron in the input layer, to do that we flatten the image to 1d tensor with shape (3072).
Now we use nn.Linear to implement the input, hidden and output layer. Check out the documentation <a href=https://pytorch.org/docs/stable/generated/torch.nn.Linear.html>here</a>. It is essentially dot-product plus adding bias. Then we add Relu activation.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e>#defining mlp</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn.functional <span style=color:#66d9ef>as</span> F
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>MLP</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>flatten <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Flatten()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>input_layer <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>3</span><span style=color:#f92672>*</span><span style=color:#ae81ff>32</span><span style=color:#f92672>*</span><span style=color:#ae81ff>32</span>, <span style=color:#ae81ff>256</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>hidden_layer <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>128</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>output_layer <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>relu <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>ReLU()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>flatten(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>relu(self<span style=color:#f92672>.</span>input_layer(x))
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>relu(self<span style=color:#f92672>.</span>hidden_layer(x))
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>output_layer(x)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> x
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>net <span style=color:#f92672>=</span> MLP()
</span></span></code></pre></div><h3 id=4-define-the-loss-and-optimizer>4. Define the loss and optimizer<a hidden class=anchor aria-hidden=true href=#4-define-the-loss-and-optimizer>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch.optim <span style=color:#66d9ef>as</span> optim
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>crit <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>CrossEntropyLoss()
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> optim<span style=color:#f92672>.</span>SGD(net<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.001</span>, momentum<span style=color:#f92672>=</span><span style=color:#ae81ff>0.9</span>)
</span></span></code></pre></div><p>You might have noticed that the output of MLP is a 1d tensor of 10 elements, but label we just have 1 label. There is no sync.
If we attempt to solve the problem like linear regression there will be significant less learning. Instead we treate output of MLP
as logits. The logit is a tensor, which gives probability of a given image belonging to particular label. The CrossEntropyLoss
helps in coverting labels to logits and we operate the loss based on applying softmax function, which gives probability. Read further
about softmax.</p><p>we use stochastic gradient descent to reach the local minima, that is update the parameters of the model through differentiation
and reach best pair of values.</p><h3 id=5-training>5. Training<a hidden class=anchor aria-hidden=true href=#5-training>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>5</span>):
</span></span><span style=display:flex><span>    running_loss <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.0</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i, data <span style=color:#f92672>in</span> enumerate(trainloader, <span style=color:#ae81ff>0</span>):
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> data
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>zero_grad()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> net(inputs)
</span></span><span style=display:flex><span>        <span style=color:#75715e># print(f&#34;output shape{outputs.shape}&#34;)</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> crit(outputs, labels)
</span></span><span style=display:flex><span>        loss<span style=color:#f92672>.</span>backward()
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>step()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        running_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> i <span style=color:#f92672>%</span> <span style=color:#ae81ff>2000</span> <span style=color:#f92672>==</span> <span style=color:#ae81ff>1999</span>:
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;[</span><span style=color:#e6db74>{</span>epoch <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>, </span><span style=color:#e6db74>{</span>i <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>:</span><span style=color:#e6db74>5d</span><span style=color:#e6db74>}</span><span style=color:#e6db74>] loss: </span><span style=color:#e6db74>{</span>running_loss <span style=color:#f92672>/</span> <span style=color:#ae81ff>2000</span><span style=color:#e6db74>:</span><span style=color:#e6db74>.3f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>            running_loss <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.0</span>
</span></span></code></pre></div><p>Perfomring SGD. Calculate loss, then compute gradient using backward (read about Autograd
<a href=https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>here</a>). Now update the params based on this gradient.
Gradient descent formula (read about it).
$$ \theta_{j+1} = \theta_j - \alpha \nabla J(\theta_j) $$</p><h3 id=6-evaluate-the-dataset>6. Evaluate the Dataset.<a hidden class=anchor aria-hidden=true href=#6-evaluate-the-dataset>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>correct <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>total <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># since we&#39;re not training, we don&#39;t need to calculate the gradients for our outputs</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> torch<span style=color:#f92672>.</span>no_grad():
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> data <span style=color:#f92672>in</span> testloader:
</span></span><span style=display:flex><span>        images, labels <span style=color:#f92672>=</span> data
</span></span><span style=display:flex><span>        <span style=color:#75715e># calculate outputs by running images through the network</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> net(images)
</span></span><span style=display:flex><span>        <span style=color:#75715e># the class with the highest energy is what we choose as prediction</span>
</span></span><span style=display:flex><span>        _, predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>max(outputs<span style=color:#f92672>.</span>data, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        total <span style=color:#f92672>+=</span> labels<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;Accuracy of the network on the 10000 test images: </span><span style=color:#e6db74>{</span><span style=color:#ae81ff>100</span> <span style=color:#f92672>*</span> correct <span style=color:#f92672>//</span> total<span style=color:#e6db74>}</span><span style=color:#e6db74> %&#39;</span>)
</span></span></code></pre></div><p>Output</p><pre tabindex=0><code class=language-output data-lang=output>Accuracy of the network on the 10000 test images: 51 %
</code></pre><h3 id=7-save-the-model>7. Save the Model<a hidden class=anchor aria-hidden=true href=#7-save-the-model>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>PATH <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;./cifar_MLP.pth&#39;</span>
</span></span><span style=display:flex><span>torch<span style=color:#f92672>.</span>save(net<span style=color:#f92672>.</span>state_dict(), PATH)
</span></span></code></pre></div><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>We have seen what is MLP, why it is ubiquitos and powerful. We trained a MLP model using pytorch through SGD.
This achieves 51 % accuracy on CIFAR-10 test dataset, which is pretty good for such a small and simple model.
Well this approach many flaws, in the whole model we treat each pixel independently we do know infer any info
of channels, neighbouring pixel relationship (we flatten) etc. But it still gives a competitive performance.
In future we will see how CNN (new type of DNN which got popular in 2010s solves these issue). Next we will check
more about pytorch ecosystem and see if we can make this model production ready.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Gokul's Website</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>