<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>OperationPass in MLIR | Gokul's Website</title>
<meta name=keywords content><meta name=description content="We will be reviewing the shape inference pass implemented in the toy chapter 4. In this article, we will be seeing how to create interface for operation and use that interface to perform modification to IR. The operation which satisfy condition for modification must implement this interface.
Interface for Operation
We can create interface for an operation by inheriting OpInterface class. We can declare the functions that the interface forces the entity to implement can be added via InterfaceMethod."><meta name=author content="Gokul"><link rel=canonical href=http://localhost:1313/posts/operationpass-in-mlir/><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/operationpass-in-mlir/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="http://localhost:1313/posts/operationpass-in-mlir/"><meta property="og:site_name" content="Gokul's Website"><meta property="og:title" content="OperationPass in MLIR"><meta property="og:description" content="We will be reviewing the shape inference pass implemented in the toy chapter 4. In this article, we will be seeing how to create interface for operation and use that interface to perform modification to IR. The operation which satisfy condition for modification must implement this interface.
Interface for Operation We can create interface for an operation by inheriting OpInterface class. We can declare the functions that the interface forces the entity to implement can be added via InterfaceMethod."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-29T00:00:00+00:00"><meta property="article:modified_time" content="2024-08-29T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="OperationPass in MLIR"><meta name=twitter:description content="We will be reviewing the shape inference pass implemented in the toy chapter 4. In this article, we will be seeing how to create interface for operation and use that interface to perform modification to IR. The operation which satisfy condition for modification must implement this interface.
Interface for Operation
We can create interface for an operation by inheriting OpInterface class. We can declare the functions that the interface forces the entity to implement can be added via InterfaceMethod."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"OperationPass in MLIR","item":"http://localhost:1313/posts/operationpass-in-mlir/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"OperationPass in MLIR","name":"OperationPass in MLIR","description":"We will be reviewing the shape inference pass implemented in the toy chapter 4. In this article, we will be seeing how to create interface for operation and use that interface to perform modification to IR. The operation which satisfy condition for modification must implement this interface.\nInterface for Operation We can create interface for an operation by inheriting OpInterface class. We can declare the functions that the interface forces the entity to implement can be added via InterfaceMethod.\n","keywords":[],"articleBody":"We will be reviewing the shape inference pass implemented in the toy chapter 4. In this article, we will be seeing how to create interface for operation and use that interface to perform modification to IR. The operation which satisfy condition for modification must implement this interface.\nInterface for Operation We can create interface for an operation by inheriting OpInterface class. We can declare the functions that the interface forces the entity to implement can be added via InterfaceMethod.\ndef ShapeInferenceOpInterface : OpInterface\u003c\"ShapeInference\"\u003e { let description = [{ Interface to access a registered method to infer the return types for an operation that can be used during type inference. }]; let methods = [ InterfaceMethod\u003c\"Infer and set the output shape for the current operation\", \"void\", \"inferShapes\"\u003e ]; } We can force an Operation to follow this interface by including it as a trait during operation definition. This is achieved by using DeclareOpInterfaceMethod and passing the interface to it. for example:\ndef CastOp : GGlowOp \u003c\"cast\", [ DeclareOpInterfaceMethods, DeclareOpInterfaceMethods, Pure, SameOperandsAndResultShape]\u003e { ... } This forces the operation to implement inferShapes() method, which writes the output shape of tensor based on arguments given.\nCreating a Operation Pass Here we create a operation pass that works on operation in gglow.func. We iterate through all the operation and check if it has dynamic shapes (unknown) and call the inferShapes() to write it. This will make all the shapes known.\nWe do this by creating a pass by inheriting mlir::PassWrapper, it has a virtual method called runOnOperation, which executed by OperationPassManager. We override this method to implement the above logic.\nstruct ShapeInferencePass : public mlir::PassWrapper\u003cShapeInferencePass, OperationPass\u003cmlir::gglow::FuncOp\u003e\u003e { ... void runOnOperation() override { auto f = getOperation(); llvm::SmallVector\u003cmlir::Operation*, 16\u003e opWorklist; f.walk([\u0026](mlir::Operation* op) { if(returnsDynamicShape(op)){ opWorklist.push_back(op); } }); for(size_t i =0; i\u003copWorklist.size(); i++) { Operation *op = opWorklist[i]; if (auto shapeOp = dyn_cast\u003cShapeInference\u003e(op)){ shapeOp.inferShapes(); } else { op-\u003eemitError(\"unable to infer shape of operation without shape \" \"inference interface\"); return signalPassFailure(); } } opWorklist.clear(); return; } ... }; Creating and Running the Operation via PassManager We create a pass manager by creating a unique pointer to the Pass.\nstd::unique_ptr\u003cmlir::Pass\u003e createShapeInferencePass(){ return std::make_unique\u003cShapeInferencePass\u003e(); } Then we create a pass manager and add the Pass:\nmlir::PassManager pm(module.get()-\u003egetName()); pm.addPass(mlir::createInlinerPass()); auto \u0026optPM = pm.nest\u003cmlir::gglow::FuncOp\u003e(); optPM.addPass(mlir::gglow::createShapeInferencePass()); optPM.addPass(mlir::createCanonicalizerPass()); Result This results in following optimization: Input:\ngglow.func @transpose_simplify(%arg0 : tensor\u003c*xf64\u003e) -\u003e tensor\u003c*xf64\u003e { %0 = gglow.transpose (%arg0: tensor\u003c*xf64\u003e) -\u003e tensor\u003c*xf64\u003e %1 = gglow.transpose (%0: tensor\u003c*xf64\u003e) -\u003e tensor\u003c*xf64\u003e gglow.return %1 : tensor\u003c*xf64\u003e } gglow.func @main() { %0 = gglow.constant ( dense\u003c[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]\u003e : tensor\u003c2x3xf64\u003e ) -\u003e tensor\u003c2x3xf64\u003e %1 = gglow.generic_call @transpose_simplify(%0) : (tensor\u003c2x3xf64\u003e) -\u003e tensor\u003c*xf64\u003e gglow.print %1 : tensor\u003c*xf64\u003e gglow.return } Output after the Pass:\ngglow.func @transpose_simplify(%arg0: tensor\u003c*xf64\u003e) -\u003e tensor\u003c*xf64\u003e { gglow.print %arg0 : tensor\u003c*xf64\u003e gglow.return %arg0 : tensor\u003c*xf64\u003e } gglow.func @main() { %0 = gglow.constant(dense\u003c[[1.000000e+00, 2.000000e+00, 3.000000e+00], [4.000000e+00, 5.000000e+00, 6.000000e+00]]\u003e : tensor\u003c2x3xf64\u003e) -\u003e tensor\u003c2x3xf64\u003e gglow.print %0 : tensor\u003c2x3xf64\u003e gglow.print %0 : tensor\u003c2x3xf64\u003e gglow.return } ","wordCount":"484","inLanguage":"en","datePublished":"2024-08-29T00:00:00Z","dateModified":"2024-08-29T00:00:00Z","author":{"@type":"Person","name":"Gokul"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/operationpass-in-mlir/"},"publisher":{"@type":"Organization","name":"Gokul's Website","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Gokul's Website (Alt + H)">Gokul's Website</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">OperationPass in MLIR</h1><div class=post-meta><span title='2024-08-29 00:00:00 +0000 UTC'>August 29, 2024</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;484 words&nbsp;·&nbsp;Gokul</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents></nav></div></details></div><div class=post-content><p>We will be reviewing the shape inference pass implemented in the toy chapter 4. In this article, we will be seeing how to create interface for operation and use that interface to perform modification to IR. The operation which satisfy condition for modification must implement this interface.</p><h1 id=interface-for-operation>Interface for Operation<a hidden class=anchor aria-hidden=true href=#interface-for-operation>#</a></h1><p>We can create interface for an operation by inheriting <code>OpInterface</code> class. We can declare the functions that the interface forces the entity to implement can be added via <code>InterfaceMethod</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-tablegen data-lang=tablegen><span style=display:flex><span><span style=color:#66d9ef>def</span> ShapeInferenceOpInterface : OpInterface&lt;<span style=color:#e6db74>&#34;ShapeInference&#34;</span>&gt; {
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> description = <span style=color:#e6db74>[{
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Interface to access a registered method to infer the return types for an
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        operation that can be used during type inference.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    }]</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> methods = [
</span></span><span style=display:flex><span>        InterfaceMethod&lt;<span style=color:#e6db74>&#34;Infer and set the output shape for the current operation&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;void&#34;</span>, <span style=color:#e6db74>&#34;inferShapes&#34;</span>&gt;
</span></span><span style=display:flex><span>    ];
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>We can force an Operation to follow this interface by including it as a trait during operation definition. This is achieved by using <code>DeclareOpInterfaceMethod</code> and passing the interface to it. for example:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-tablegen data-lang=tablegen><span style=display:flex><span><span style=color:#66d9ef>def</span> CastOp : GGlowOp &lt;<span style=color:#e6db74>&#34;cast&#34;</span>, [ 
</span></span><span style=display:flex><span>    DeclareOpInterfaceMethods&lt;CastOpInterface&gt;,
</span></span><span style=display:flex><span>    DeclareOpInterfaceMethods&lt;ShapeInferenceOpInterface&gt;,
</span></span><span style=display:flex><span>    Pure, 
</span></span><span style=display:flex><span>    SameOperandsAndResultShape]&gt; {
</span></span><span style=display:flex><span>    ...
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>This forces the operation to implement <code>inferShapes()</code> method, which writes the output shape of tensor based on arguments given.</p><h1 id=creating-a-operation-pass>Creating a Operation Pass<a hidden class=anchor aria-hidden=true href=#creating-a-operation-pass>#</a></h1><p>Here we create a operation pass that works on operation in <code>gglow.func</code>. We iterate through all the operation and check if it has dynamic shapes (unknown) and call the <code>inferShapes()</code> to write it. This will make all the shapes known.</p><p>We do this by creating a pass by inheriting <code>mlir::PassWrapper</code>, it has a virtual method called <code>runOnOperation</code>, which executed by <code>OperationPassManager</code>. We override this method to implement the above logic.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=display:flex><span><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>ShapeInferencePass</span> <span style=color:#f92672>:</span> <span style=color:#66d9ef>public</span> mlir<span style=color:#f92672>::</span>PassWrapper<span style=color:#f92672>&lt;</span>ShapeInferencePass, OperationPass<span style=color:#f92672>&lt;</span>mlir<span style=color:#f92672>::</span>gglow<span style=color:#f92672>::</span>FuncOp<span style=color:#f92672>&gt;&gt;</span> {
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>void</span> runOnOperation() <span style=color:#66d9ef>override</span> {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>auto</span> f <span style=color:#f92672>=</span> getOperation();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        llvm<span style=color:#f92672>::</span>SmallVector<span style=color:#f92672>&lt;</span>mlir<span style=color:#f92672>::</span>Operation<span style=color:#f92672>*</span>, <span style=color:#ae81ff>16</span><span style=color:#f92672>&gt;</span> opWorklist;
</span></span><span style=display:flex><span>        f.walk([<span style=color:#f92672>&amp;</span>](mlir<span style=color:#f92672>::</span>Operation<span style=color:#f92672>*</span> op) {
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span>(returnsDynamicShape(op)){
</span></span><span style=display:flex><span>                opWorklist.push_back(op);
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        });
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span>(size_t i <span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>; i<span style=color:#f92672>&lt;</span>opWorklist.size(); i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>            Operation <span style=color:#f92672>*</span>op <span style=color:#f92672>=</span> opWorklist[i];
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> (<span style=color:#66d9ef>auto</span> shapeOp <span style=color:#f92672>=</span> dyn_cast<span style=color:#f92672>&lt;</span>ShapeInference<span style=color:#f92672>&gt;</span>(op)){
</span></span><span style=display:flex><span>                shapeOp.inferShapes();
</span></span><span style=display:flex><span>            } <span style=color:#66d9ef>else</span> {
</span></span><span style=display:flex><span>                op<span style=color:#f92672>-&gt;</span>emitError(<span style=color:#e6db74>&#34;unable to infer shape of operation without shape &#34;</span>
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#34;inference interface&#34;</span>);
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>return</span> <span style=color:#a6e22e>signalPassFailure</span>();
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        opWorklist.clear();
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span>;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>};
</span></span></code></pre></div><h1 id=creating-and-running-the-operation-via-passmanager>Creating and Running the Operation via PassManager<a hidden class=anchor aria-hidden=true href=#creating-and-running-the-operation-via-passmanager>#</a></h1><p>We create a pass manager by creating a unique pointer to the Pass.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=display:flex><span>std<span style=color:#f92672>::</span>unique_ptr<span style=color:#f92672>&lt;</span>mlir<span style=color:#f92672>::</span>Pass<span style=color:#f92672>&gt;</span> createShapeInferencePass(){
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> std<span style=color:#f92672>::</span>make_unique<span style=color:#f92672>&lt;</span>ShapeInferencePass<span style=color:#f92672>&gt;</span>();
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Then we create a pass manager and add the Pass:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=display:flex><span>mlir<span style=color:#f92672>::</span>PassManager pm(module.get()<span style=color:#f92672>-&gt;</span>getName());
</span></span><span style=display:flex><span>pm.addPass(mlir<span style=color:#f92672>::</span>createInlinerPass());
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>auto</span> <span style=color:#f92672>&amp;</span>optPM <span style=color:#f92672>=</span> pm.nest<span style=color:#f92672>&lt;</span>mlir<span style=color:#f92672>::</span>gglow<span style=color:#f92672>::</span>FuncOp<span style=color:#f92672>&gt;</span>();
</span></span><span style=display:flex><span>optPM.addPass(mlir<span style=color:#f92672>::</span>gglow<span style=color:#f92672>::</span>createShapeInferencePass());
</span></span><span style=display:flex><span>optPM.addPass(mlir<span style=color:#f92672>::</span>createCanonicalizerPass());
</span></span></code></pre></div><h1 id=result>Result<a hidden class=anchor aria-hidden=true href=#result>#</a></h1><p>This results in following optimization:
Input:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-mlir data-lang=mlir><span style=display:flex><span>gglow.<span style=color:#66d9ef>func</span> <span style=color:#a6e22e>@transpose_simplify</span>(%arg0 : <span style=color:#66d9ef>tensor</span>&lt;*xf64&gt;) -&gt; <span style=color:#66d9ef>tensor</span>&lt;*xf64&gt; {
</span></span><span style=display:flex><span>	%0 = gglow.transpose (%arg0: <span style=color:#66d9ef>tensor</span>&lt;*xf64&gt;) -&gt; <span style=color:#66d9ef>tensor</span>&lt;*xf64&gt;
</span></span><span style=display:flex><span>	%1 = gglow.transpose (%0: <span style=color:#66d9ef>tensor</span>&lt;*xf64&gt;) -&gt; <span style=color:#66d9ef>tensor</span>&lt;*xf64&gt;
</span></span><span style=display:flex><span>	gglow.<span style=color:#66d9ef>return</span> %1 : <span style=color:#66d9ef>tensor</span>&lt;*xf64&gt;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>gglow.<span style=color:#66d9ef>func</span> <span style=color:#a6e22e>@main</span>() {
</span></span><span style=display:flex><span>	%0 = gglow.<span style=color:#66d9ef>constant</span> ( dense&lt;[[<span style=color:#ae81ff>1.0</span>, <span style=color:#ae81ff>2.0</span>, <span style=color:#ae81ff>3.0</span>], [<span style=color:#ae81ff>4.0</span>, <span style=color:#ae81ff>5.0</span>, <span style=color:#ae81ff>6.0</span>]]&gt;
</span></span><span style=display:flex><span>		: <span style=color:#66d9ef>tensor</span>&lt;<span style=color:#ae81ff>2x3x</span><span style=color:#66d9ef>f64</span>&gt; ) -&gt; <span style=color:#66d9ef>tensor</span>&lt;<span style=color:#ae81ff>2x3x</span><span style=color:#66d9ef>f64</span>&gt;
</span></span><span style=display:flex><span>	%1 = gglow.generic_call <span style=color:#a6e22e>@transpose_simplify</span>(%0) : (<span style=color:#66d9ef>tensor</span>&lt;<span style=color:#ae81ff>2x3x</span><span style=color:#66d9ef>f64</span>&gt;) -&gt; <span style=color:#66d9ef>tensor</span>&lt;*xf64&gt;
</span></span><span style=display:flex><span>	gglow.print %1 : <span style=color:#66d9ef>tensor</span>&lt;*xf64&gt;
</span></span><span style=display:flex><span>	gglow.<span style=color:#66d9ef>return</span>
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Output after the Pass:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-mlir data-lang=mlir><span style=display:flex><span>  gglow.<span style=color:#66d9ef>func</span> <span style=color:#a6e22e>@transpose_simplify</span>(%arg0: <span style=color:#66d9ef>tensor</span>&lt;*xf64&gt;) -&gt; <span style=color:#66d9ef>tensor</span>&lt;*xf64&gt; {
</span></span><span style=display:flex><span>    gglow.print %arg0 : <span style=color:#66d9ef>tensor</span>&lt;*xf64&gt;
</span></span><span style=display:flex><span>    gglow.<span style=color:#66d9ef>return</span> %arg0 : <span style=color:#66d9ef>tensor</span>&lt;*xf64&gt;
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>  gglow.<span style=color:#66d9ef>func</span> <span style=color:#a6e22e>@main</span>() {
</span></span><span style=display:flex><span>    %0 = gglow.<span style=color:#66d9ef>constant</span>(dense&lt;[[<span style=color:#ae81ff>1.000000e+00</span>, <span style=color:#ae81ff>2.000000e+00</span>, <span style=color:#ae81ff>3.000000e+00</span>], [<span style=color:#ae81ff>4.000000e+00</span>, <span style=color:#ae81ff>5.000000e+00</span>, <span style=color:#ae81ff>6.000000e+00</span>]]&gt; : <span style=color:#66d9ef>tensor</span>&lt;<span style=color:#ae81ff>2x3x</span><span style=color:#66d9ef>f64</span>&gt;) -&gt; <span style=color:#66d9ef>tensor</span>&lt;<span style=color:#ae81ff>2x3x</span><span style=color:#66d9ef>f64</span>&gt;
</span></span><span style=display:flex><span>    gglow.print %0 : <span style=color:#66d9ef>tensor</span>&lt;<span style=color:#ae81ff>2x3x</span><span style=color:#66d9ef>f64</span>&gt;
</span></span><span style=display:flex><span>    gglow.print %0 : <span style=color:#66d9ef>tensor</span>&lt;<span style=color:#ae81ff>2x3x</span><span style=color:#66d9ef>f64</span>&gt;
</span></span><span style=display:flex><span>    gglow.<span style=color:#66d9ef>return</span>
</span></span><span style=display:flex><span>  }
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Gokul's Website</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>