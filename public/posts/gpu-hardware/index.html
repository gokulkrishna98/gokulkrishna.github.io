<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>GPU Hardware | Gokul's Website</title>
<meta name=keywords content><meta name=description content="In this article, we will have a brief overview of GPU Hardware from programming perspective. I am a software engineer and I do not have time or resources to learn nitty-gritty details of hardware engineering. However, learning about hardware is essential to write efficient and clean programs. I have learned it hard way during my stint at Samsung. We will be looking at discrete GPU setup, then understand how modern NVIDIA GPUs look like and then try to understand each part (from NVIDIA whitepaper)"><meta name=author content="Gokul"><link rel=canonical href=http://localhost:1313/posts/gpu-hardware/><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/gpu-hardware/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="http://localhost:1313/posts/gpu-hardware/"><meta property="og:site_name" content="Gokul's Website"><meta property="og:title" content="GPU Hardware"><meta property="og:description" content="In this article, we will have a brief overview of GPU Hardware from programming perspective. I am a software engineer and I do not have time or resources to learn nitty-gritty details of hardware engineering. However, learning about hardware is essential to write efficient and clean programs. I have learned it hard way during my stint at Samsung. We will be looking at discrete GPU setup, then understand how modern NVIDIA GPUs look like and then try to understand each part (from NVIDIA whitepaper)"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-08T00:00:00+00:00"><meta property="article:modified_time" content="2024-09-08T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="GPU Hardware"><meta name=twitter:description content="In this article, we will have a brief overview of GPU Hardware from programming perspective. I am a software engineer and I do not have time or resources to learn nitty-gritty details of hardware engineering. However, learning about hardware is essential to write efficient and clean programs. I have learned it hard way during my stint at Samsung. We will be looking at discrete GPU setup, then understand how modern NVIDIA GPUs look like and then try to understand each part (from NVIDIA whitepaper)"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"GPU Hardware","item":"http://localhost:1313/posts/gpu-hardware/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"GPU Hardware","name":"GPU Hardware","description":"In this article, we will have a brief overview of GPU Hardware from programming perspective. I am a software engineer and I do not have time or resources to learn nitty-gritty details of hardware engineering. However, learning about hardware is essential to write efficient and clean programs. I have learned it hard way during my stint at Samsung. We will be looking at discrete GPU setup, then understand how modern NVIDIA GPUs look like and then try to understand each part (from NVIDIA whitepaper)\n","keywords":[],"articleBody":"In this article, we will have a brief overview of GPU Hardware from programming perspective. I am a software engineer and I do not have time or resources to learn nitty-gritty details of hardware engineering. However, learning about hardware is essential to write efficient and clean programs. I have learned it hard way during my stint at Samsung. We will be looking at discrete GPU setup, then understand how modern NVIDIA GPUs look like and then try to understand each part (from NVIDIA whitepaper)\nDiscrete GPU Setup Discrete GPU setup is where we have GPU Hardware that is coupled away from CPU and communicate with CPU using PCIe/NVLink connections and driver code. The other kind would be integrated GPU, where GPU silicon which is part of SoC and shares memory with CPU. The figure below is a typical CPU-GPU Setup. Structure of a typical CPU-GPU Setup. source: here\nBefore starting comparison, let us see what is PCI-Express ? Peripheral Component Interconnect Express is a type of hardware connection that enables high speed data transfer between two components. It is a standard based on current technological needs and technology (similar to USB Type C), and hardware people can have simple time designing for connection.\nLet us notice few differences between CPU and GPU:\nSize each ALUs in GPU is smaller compared to CPU. Smaller Cache and Control Unit sizes in GPUs compared to CPU. Number of ALUs in GPU is way bigger compared to CPU. DRAM is different in CPU and GPU. All these difference are due to trade-off decision taken by GPU Hardware engineer to deliver maximum floating point operations per second. So, CPUs have lot of features like:\nhardware hyper-threading enabling speculative execution to deliver absolute speed in sequential operation. CPU provide low latency memory access via complex cache design. CPUs have sophisticated control units like branch prediction. GPU hardware designers removed (not removed, they designed it, using this as i do not know nitty gritty details of hardware) these unnecessary features from CPU and freed lot of transistor counts to create more GPU ALU units. The DRAM in GPU is designed for high bandwidth memory access and not for low latency like CPUs. In CPU-GPU setup, the CPU is called a host and transfers huge data-parallel task to GPU along with kernels needed for execution. The above GPU view is very rudimentary, lets start learning the real world stuff.\nL (O.o) king inside the GPUs. Let us peep into Ampere architecture (the famous A100 GPUs). These GPUs share similarity with Fermi Architecture, so it is very easy to understand latest hardware. First, let us understand few terminology.\nStreaming processors (SP) : These are the individual cores that does the arithmetic operations. Streaming multi-processors (SM) : The SPs are grouped into units called SMs. The SPs in the same SMs can share memory, special computation units etc. From programming perspective:\nThread: it is individual computation defined by user that can be executed by SPs. Blocks: These are grouping of thread, based on how these threads need to executed. For example, a block of threads is executed in the same single SM. First we will view the GPU as a collection of SM, later we will look into the SMs as a collection of SP. I feel this provide two different perspective of GPU Hardware.\nNVIDIA Ampere GA104 architecture. source: here\nThere is lot to unpack here, these aspects and grouping is related to computer graphics and can be used via vulkan/opengl. I am just going to give brief description on these part and not go indepth.\nLet us have brief functionality of each part:\nGiga-Thread Engine: One of the key feature in modern GPUs is the ability to run several kernels in parallel on the same device. All the blocks from different kernels are first given to top-level scheduler (called the Giga-Thread Engine). It is responsible for dispatching blocks to SMs. This dispatching can be dynamic, takes into account of future loads and asynchronous. Memory Controller: Memory controllers contain the logic necessary to read and write to dynamic random-access memory(DRAM), and to provide the critical memory refresh and other functions. It also connects various memory units to the main processor bus system. GPU processing cluster (GPC): The Graphics Processing Cluster (GPC) is a dedicated hardware block for computing, rasterization, shading, and texturing. These are terminologies are related to computer graphics. The GPC consist of set of TPC, Raster engine and ROP units. Raster Engine: The raster engine converts vector graphics (such as 3D models) into raster images (pixels). This enables SPs to execute on these pixels instead of doing complex conversion task. ROP units: Raster Operations Pipelines (ROPs) are responsible for the final stages of pixel processing before the image is displayed on the screen. They perform computation for blending, depth testing, gamma correction etc. Texture processing cluster (TPC): TPCs are responsible for executing the core graphic workloads that make up the visual experience we see on our screens. They handle functionality of mapping texture, fragment shading, vertex shading etc and they have computation units needed for this task. They contain polymorph engine and set of SMs. Polymorph Engine: I do not know much about it, but the hardware units present here is responsible for vertex shading, geometry and texture processing. Now let us look into the main part which does the parallel computation, the SMs.\nImage of a Streaming Multi-processor (SM)\nSM consists of -\nWarp Scheduler: It performs the action of swapping busy warps to save time, this results in latency hiding. Dispatch Unit: Dispatch unit assigns warps to the cores, so that everything can run parallel. Int32 and FP32 cores: These are the cores that perform simple arithmetic operation. Tensor Cores: These are the core, with special units for machine learning related operation. (latest H100, there is even transformer engine). LD/ST: These are the load and store units, which access memory needed for the computation. SFU: These are special functional unit, that handle computation like erf, sin, cos etc. Raytracing cores: These are special hardware units, needed to perform fast but heavy ray-tracing computation. How does GPU programming maps to Execution on Hardware ? A Story Tale. Will be posting on this soon. Cooking\nReferences Warp-Level Parallelism: Enabling Multiple Replications In Parallel on GPU GPC GPU Introduction Article from cudocompute ","wordCount":"1054","inLanguage":"en","datePublished":"2024-09-08T00:00:00Z","dateModified":"2024-09-08T00:00:00Z","author":{"@type":"Person","name":"Gokul"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/gpu-hardware/"},"publisher":{"@type":"Organization","name":"Gokul's Website","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Gokul's Website (Alt + H)">Gokul's Website</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">GPU Hardware</h1><div class=post-meta><span title='2024-09-08 00:00:00 +0000 UTC'>September 8, 2024</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;1054 words&nbsp;·&nbsp;Gokul</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#discrete-gpu-setup>Discrete GPU Setup</a></li><li><a href=#l-oo-king-inside-the-gpus>L (O.o) king inside the GPUs.</a></li><li><a href=#how-does-gpu-programming-maps-to-execution-on-hardware--a-story-tale>How does GPU programming maps to Execution on Hardware ? A Story Tale.</a></li><li><a href=#references>References</a></li></ul></nav></div></details></div><div class=post-content><p>In this article, we will have a brief overview of GPU Hardware from programming perspective. I am a software engineer and I do not have time or resources to learn nitty-gritty details of hardware engineering. However, learning about hardware is essential to write efficient and clean programs. I have learned it hard way during my stint at Samsung. We will be looking at discrete GPU setup, then understand how modern NVIDIA GPUs look like and then try to understand each part (from NVIDIA whitepaper)</p><h2 id=discrete-gpu-setup>Discrete GPU Setup<a hidden class=anchor aria-hidden=true href=#discrete-gpu-setup>#</a></h2><p>Discrete GPU setup is where we have GPU Hardware that is coupled away from CPU and communicate with CPU using PCIe/NVLink connections and driver code. The other kind would be integrated GPU, where GPU silicon which is part of SoC and shares memory with CPU. The figure below is a typical CPU-GPU Setup.
<img alt="cpu-gpu setup" loading=lazy src=/images/d00e8d044fecd4049f9a13cd274bf399.png></p><p>Structure of a typical CPU-GPU Setup.
source: <a href=https://enccs.github.io/gpu-programming/2-gpu-ecosystem/>here</a></p><p>Before starting comparison, let us see what is PCI-Express ? Peripheral Component Interconnect Express is a type of hardware connection that enables high speed data transfer between two components. It is a standard based on current technological needs and technology (similar to USB Type C), and hardware people can have simple time designing for connection.</p><p>Let us notice few differences between CPU and GPU:</p><ol><li>Size each ALUs in GPU is smaller compared to CPU.</li><li>Smaller Cache and Control Unit sizes in GPUs compared to CPU.</li><li>Number of ALUs in GPU is way bigger compared to CPU.</li><li>DRAM is different in CPU and GPU.</li></ol><p>All these difference are due to trade-off decision taken by GPU Hardware engineer to deliver maximum floating point operations per second. So, CPUs have lot of features like:</p><ul><li>hardware hyper-threading enabling speculative execution to deliver absolute speed in sequential operation.</li><li>CPU provide low latency memory access via complex cache design.</li><li>CPUs have sophisticated control units like branch prediction.
GPU hardware designers removed (not removed, they designed it, using this as i do not know nitty gritty details of hardware) these unnecessary features from CPU and freed lot of transistor counts to create more GPU ALU units. The DRAM in GPU is designed for high bandwidth memory access and not for low latency like CPUs.</li></ul><p>In CPU-GPU setup, the CPU is called a <code>host</code> and transfers huge data-parallel task to GPU along with kernels needed for execution. The above GPU view is very rudimentary, lets start learning the real world stuff.</p><h2 id=l-oo-king-inside-the-gpus>L (O.o) king inside the GPUs.<a hidden class=anchor aria-hidden=true href=#l-oo-king-inside-the-gpus>#</a></h2><p>Let us peep into Ampere architecture (the famous A100 GPUs). These GPUs share similarity with Fermi Architecture, so it is very easy to understand latest hardware. First, let us understand few terminology.</p><ul><li>Streaming processors (SP) : These are the individual cores that does the arithmetic operations.</li><li>Streaming multi-processors (SM) : The SPs are grouped into units called SMs. The SPs in the same SMs can share memory, special computation units etc.</li></ul><p>From programming perspective:</p><ul><li>Thread: it is individual computation defined by user that can be executed by SPs.</li><li>Blocks: These are grouping of thread, based on how these threads need to executed. For example, a block of threads is executed in the same single SM.</li></ul><p>First we will view the GPU as a collection of SM, later we will look into the SMs as a collection of SP. I feel this provide two different perspective of GPU Hardware.</p><p><img alt="GA104 arch" loading=lazy src=/images/04bfd9cad039e9686b64c209b69de47f.png>
NVIDIA Ampere GA104 architecture.
source: <a href=https://wolfadvancedtechnology.com/articles/nvidia-gpu-architecture>here</a></p><p>There is lot to unpack here, these aspects and grouping is related to computer graphics and can be used via vulkan/opengl. I am just going to give brief description on these part and not go indepth.</p><p>Let us have brief functionality of each part:</p><ul><li><strong>Giga-Thread Engine:</strong> One of the key feature in modern GPUs is the ability to run several kernels in parallel on the same device. All the blocks from different kernels are first given to top-level scheduler (called the Giga-Thread Engine). It is responsible for dispatching blocks to SMs. This dispatching can be dynamic, takes into account of future loads and asynchronous.</li><li><strong>Memory Controller:</strong> Memory controllers contain the logic necessary to read and write to dynamic random-access memory(DRAM), and to provide the critical <a href=https://en.wikipedia.org/wiki/Memory_refresh title="Memory refresh">memory refresh</a> and other functions. It also connects various memory units to the main processor bus system.</li><li><strong>GPU processing cluster (GPC)</strong>: The Graphics Processing Cluster (GPC) is a dedicated hardware block for computing, rasterization, shading, and texturing. These are terminologies are related to computer graphics. The GPC consist of set of TPC, Raster engine and ROP units.</li><li><strong>Raster Engine:</strong> The raster engine converts vector graphics (such as 3D models) into raster images (pixels). This enables SPs to execute on these pixels instead of doing complex conversion task.</li><li><strong>ROP units:</strong> Raster Operations Pipelines (ROPs) are responsible for the final stages of pixel processing before the image is displayed on the screen. They perform computation for blending, depth testing, gamma correction etc.</li><li><strong>Texture processing cluster (TPC):</strong> TPCs are responsible for executing the core graphic workloads that make up the visual experience we see on our screens. They handle functionality of mapping texture, fragment shading, vertex shading etc and they have computation units needed for this task. They contain polymorph engine and set of SMs.</li><li><strong>Polymorph Engine:</strong> I do not know much about it, but the hardware units present here is responsible for vertex shading, geometry and texture processing.</li></ul><p>Now let us look into the main part which does the parallel computation, the SMs.</p><p><img alt="GA104 arch" loading=lazy src=/images/3ac4a2114f22737e9e50effeeda8efec.png>
Image of a Streaming Multi-processor (SM)</p><p>SM consists of -</p><ul><li><strong>Warp Scheduler:</strong> It performs the action of swapping busy warps to save time, this results in latency hiding.</li><li><strong>Dispatch Unit:</strong> Dispatch unit assigns warps to the cores, so that everything can run parallel.</li><li><strong>Int32 and FP32 cores:</strong> These are the cores that perform simple arithmetic operation.</li><li><strong>Tensor Cores:</strong> These are the core, with special units for machine learning related operation. (latest H100, there is even transformer engine).</li><li><strong>LD/ST:</strong> These are the load and store units, which access memory needed for the computation.</li><li><strong>SFU:</strong> These are special functional unit, that handle computation like erf, sin, cos etc.</li><li><strong>Raytracing cores:</strong> These are special hardware units, needed to perform fast but heavy ray-tracing computation.</li></ul><h2 id=how-does-gpu-programming-maps-to-execution-on-hardware--a-story-tale>How does GPU programming maps to Execution on Hardware ? A Story Tale.<a hidden class=anchor aria-hidden=true href=#how-does-gpu-programming-maps-to-execution-on-hardware--a-story-tale>#</a></h2><p>Will be posting on this soon. Cooking</p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><ul><li><a href=https://arxiv.org/abs/1501.01405>Warp-Level Parallelism: Enabling Multiple Replications In Parallel on GPU</a></li><li><a href=https://developer.ridgerun.com/wiki/index.php/Xavier/Processors/GPU/Description#Graphics_Processing_Cluster>GPC</a></li><li><a href=https://www.cudocompute.com/blog/a-beginners-guide-to-nvidia-gpus>GPU Introduction Article from cudocompute</a></li></ul></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Gokul's Website</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>